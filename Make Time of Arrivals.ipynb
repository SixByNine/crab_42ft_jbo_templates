{"cells":[{"cell_type":"code","execution_count":null,"id":"b1aa88b7","metadata":{"id":"b1aa88b7"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.optimize as opt\n","import os"]},{"cell_type":"markdown","id":"8ed183f8","metadata":{"id":"8ed183f8"},"source":["# Measuring the \"time of arrival\" of a pulsar\n","## Crab Pulsar Experiment Part 3.2\n","\n","This notebook can be used for the first part of the crab timing part of the experiment. Here you will find code that reads your data files (pulsar archives) and matches the observed pulse against a _standard template_ of the crab pulsar. This standard template is a noise-free model of the shape of the pulse and we can measure the time that the pulse arrived to very high precision by correlating the known shape of the pulse (the template) with the noisy data.\n","\n","The code is in four main parts:\n"," 1. Specifying the data location\n"," 2. Dedispersion of the data ( **insert your code from Part 1 here** )\n"," 3. Measuring the time of arrival (ToA)\n"," 4. Visualising the result\n"," \n","_You will need to run all three parts in sequence to get the right results._ Visualising the output is important to be sure you have got sensible results.\n","\n"]},{"cell_type":"markdown","id":"c3b8e5de","metadata":{"id":"c3b8e5de"},"source":["# Load Data"]},{"cell_type":"code","source":["# Connect (mount) your google drive as a virtual directory accessible by this python code.\n","from google.colab import drive         # Import the python module that allows you to access your google drive\n","rootpathdrive = '/content/drive'       # This will be the directory as which your google drive will be known\n","drive.mount(rootpathdrive)             # Now connect to this google drive. \n","\n","# At first use it will ask you to click on a link, after which you should give permission \n","# for outside processes to access your google drive. A authorization code is generated which should be entered \n","#(this is explained in https://colab.research.google.com/notebooks/io.ipynb#scrollTo=XDg9OBaYqRMd)."],"metadata":{"id":"kYUxVMeKYguy"},"id":"kYUxVMeKYguy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A good test to do is if you can see the contents of the directory in which you work on your google drive.\n","# Here \"My Drive\" refers to the \"root\" of your google drive.\n","# By default your notebook should be in a directory called Colab Notebooks.\n","# This template assumes all files you want to read in are copied in the\n","# same directory. Note the slash at the end of the first line.\n","pathcrabtemplate = rootpathdrive+'/'+'My Drive/Crab_pulsar_template/'\n","filelist = []\n","for (dirpath, dirnames, filenames) in os.walk(pathcrabtemplate):\n","    filelist.extend(filenames)\n","    break\n","print (filelist)   # Show the contents of your working directory. At least your notebook should show up here."],"metadata":{"id":"0d8r4cO4YoN_"},"id":"0d8r4cO4YoN_","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c2642e5e","metadata":{"id":"c2642e5e"},"outputs":[],"source":["filename=os.path.join(pathcrabtemplate,\"mydata/20220907_233401_B0531+21.npz\")# Enter the filename of your data here\n","obsdata = np.load(filename)\n","print(obsdata['header'])\n","data=obsdata['data']\n","\n","print(\"'Guess Period':\",obsdata['approx_period'])"]},{"cell_type":"code","execution_count":null,"id":"d75b54de","metadata":{"id":"d75b54de"},"outputs":[],"source":["templatefilename=os.path.join(pathcrabtemplate,\"template.txt\")# Enter the filename of your data here\n","template=np.loadtxt(templatefilename)\n","plt.plot(template)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e5837bfc","metadata":{"id":"e5837bfc"},"outputs":[],"source":["##\n","#  This function will shift each row of a 2-d (3-d) array by the the number of columns specified in the \"shifts\" array.\n","#  data_in - the 2-d (3-d) array to work on\n","#  shifts - the shifts to apply\n","#  Returns: The shifted array\n","##\n","def shift_rows(data_in, shifts):\n","    shifted = np.zeros_like(data_in)\n","    if data_in.ndim == 3:\n","        for i in range(data_in.shape[0]):\n","            shifted[i] = shift_rows(data_in[i],shifts)\n","    else:\n","        for i in range(data_in.shape[0]):\n","            shifted[i] = np.roll(data_in[i],int(shifts[i]))\n","    return shifted\n"]},{"cell_type":"markdown","id":"83efc8ba","metadata":{"id":"83efc8ba"},"source":["## Computing the time of arrivals\n","**Please don't worry too much about how this code works.** This is based on research software used for experiments ranging searching for planets around pulsars to measuring gravitational waves passing over the earth. It has been annotated with a few comments for the curious, but you can mostly just treat this as a black box you can use to get time of arrival measurements for your pulsar data.\n","If you are desparate to dig into the details, this code is based on the ToA estimation procedure described in Appendix A of Taylor et al. 1992. (https://www.jstor.org/stable/53915)"]},{"cell_type":"code","execution_count":null,"id":"663cc399","metadata":{"scrolled":true,"id":"663cc399"},"outputs":[],"source":["\n","def get_toas(ddfreq_averaged,obsdata,plots=True):\n","    \n","    times=obsdata['times'] # The time of phase zero for each subint\n","    approx_period=obsdata['approx_period'] # The approximate period of the pulsar\n","    toas=[]\n","    toa_errs=[]\n","    tempo2_toas=[]\n","\n","    # Equation A7 in Taylor 1992\n","    def get_dchi(tau,N,nbin):\n","        dphi = np.angle(xspec)[1:N]\n","\n","        k=np.arange(1,N)\n","\n","        dchi = np.sum(k*np.abs(f_prof[1:N])*np.abs(f_template[1:N]) * np.sin(dphi + 2*np.pi*k*tau/nbin))\n","        return dchi\n","\n","\n","    # Equation A9 in Taylor 1992\n","    def get_b(tau,N,nbin):\n","        dphi = np.angle(xspec)[1:N]\n","        k=np.arange(1,N)\n","        scale = np.sum(np.abs(f_prof[1:N])*np.abs(f_template[1:N]) * np.cos(dphi + 2*np.pi*k*tau/nbin))\n","        scale /= np.sum(np.abs(f_template[1:N])**2)\n","        return scale\n","\n","\n","    # Equation A10 in Taylor 1992\n","    def get_sigma_tau(tau,N,nbin,b):\n","        dphi = np.angle(xspec)[1:N]\n","        k=np.arange(1,N)\n","        chi2=np.sum(np.abs(f_prof[1:N])**2 + b**2*np.abs(f_template[1:N]) )-2*b*np.sum(np.abs(f_prof[1:N])*np.abs(f_template[1:N]) * np.cos(dphi + 2*np.pi*k*tau/nbin))\n","        sigma2 = chi2/(N-1)\n","        de = np.sum((k**2) * np.abs(f_prof[1:N])*np.abs(f_template[1:N]) * np.cos(dphi + 2*np.pi*k*tau/nbin))\n","        fac=nbin/(2*np.pi)\n","        return np.sqrt(sigma2/(2*b*de))*fac\n","\n","    # Just for plotting, rotates an array by a fractional phase shift using Fourier transform\n","    def rotate_phs(ff,phase_shift):\n","        fr = ff*np.exp(1.0j*2*np.pi*np.arange(len(ff))*phase_shift)\n","        return np.fft.irfft(fr)\n","\n","    \n","    # Loop over every sub integration\n","    for ip in range(len(ddfreq_averaged)):\n","        prof=ddfreq_averaged[ip]\n","        nbin=len(prof)\n","\n","        # We are going to do a cross correlation by means of the Fourier transform and the Wiener-Kinchin theorem\n","        f_template = np.fft.rfft(template)\n","        f_prof = np.fft.rfft(prof)\n","\n","        # The cross correlation of a and b is the inverse transform of FT(a) times the conjugate of FT(b)\n","        xspec= f_template * f_prof.conj() # \"cross spectrum\"\n","        xcor = np.fft.irfft(xspec) # Cross correlation\n","\n","        ishift = np.argmax(np.abs(xcor)) # estimate of the shift directly from the peak cross-correlation\n","\n","        # We need to define some bounds to search. (Actually this might not be optimal)\n","        lo=ishift-1\n","        hi=ishift+1\n","        nh=len(xspec)\n","        # We minimise the chisquare parameter by findng the root of it's derivatiive following Taylor 1992 \n","        # This root_scalar method uses the 'Brent 1973' algorithm for root finding.\n","        ret = opt.root_scalar(get_dchi,bracket=(lo,hi),x0=ishift,args=(nh,nbin),method='brentq')\n","\n","        # tau is the bin shift between data and template, which will become our ToA\n","        tau=ret.root\n","        # Again folow the math of Taylor 1992 to get the scale factor, which it calls 'b'\n","        scale=get_b(tau,nh,nbin)\n","        # And finally given the shift and scale we can find the uncertainty on the shift.\n","        sigma_tau=get_sigma_tau(tau,nh,nbin,scale)\n","\n","        # Phase shift is bin shift divided by nbins\n","        phase_shift = tau/nbin\n","\n","        # ToA is the phase shift converted to a time shift and added to the time of phase zero.\n","        toa = times[ip]+approx_period*tau/nbin/86400.0\n","        toa_err = approx_period*sigma_tau/nbin\n","        tempo2_toa=\" test 611 {:.16f} {} jb42\\n\".format(toa,toa_err)\n","\n","        toas.append(toa)\n","        toa_errs.append(toa_err)\n","        tempo2_toas.append(tempo2_toa)\n","\n","        phase=np.linspace(0,1,nbin)\n","\n","        rotate_and_scaled_template=scale*rotate_phs(f_template,phase_shift)\n","        diff=prof-rotate_and_scaled_template\n","\n","        d= np.amax(prof)-np.amin(prof)\n","        if plots:\n","            # And do some plotting...\n","            plt.figure(figsize=(12,8))\n","            plt.xlabel(\"Pulse Phase\")\n","            plt.ylabel(\"Flux Density (arbitrary)\")\n","\n","            plt.title(r\"{} Profile {:d}:  $\\delta t =$ {:.3f} $\\pm$ {:.3f} ms\".format(obsdata['source_name'],ip,1e3*approx_period*phase_shift,1e3*toa_err))\n","            plt.step(phase,prof,color='black',linewidth=1.0,label=\"Data\")\n","            plt.plot(phase,rotate_and_scaled_template,color='red',label=\"Template\")\n","\n","            plt.step(phase,diff-d,color='green',linewidth=1.0,alpha=0.8,label=r\"Data$-$template\")\n","            plt.axhline(-d,ls=\":\",color='k')\n","\n","            plt.xlim(0,1)\n","            plt.ylim(np.amin(prof)-1.2*d,np.amax(prof)+0.1*d)\n","\n","            plt.legend(loc=\"lower left\",ncol=3)\n","\n","            plt.show()\n","            plt.close()\n","    return np.array(toas),np.array(toa_errs)\n"]},{"cell_type":"code","execution_count":null,"id":"20200b8a","metadata":{"id":"20200b8a"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4045b498","metadata":{"id":"4045b498"},"source":["# Your code - Dedisperse and make the ToAs\n","Here you can insert your dedispersion code from part 1, and then call the function to make toas"]},{"cell_type":"code","execution_count":null,"id":"d9643879","metadata":{"id":"d9643879"},"outputs":[],"source":["## Insert your de-dispersion code here\n","# ... \n","# Create a de-dispersed frequency-averaged data called ddfreq_averaged\n","# ddfreq_averaged = \n","#\n","nsub, nchan,nphase = data.shape\n","ichan=np.arange(nchan)\n","\n","toas,toa_errs = get_toas(ddfreq_averaged, obsdata)\n","\n","with open(filename+\".toas.txt\",\"w\") as outf:\n","    for t,e in zip(toas,toa_errs):\n","        print(\"{:.18f} {:.3g}\".format(t,e))\n","        outf.write(\"{:.18f} {:.3g}\\n\".format(t,e))"]},{"cell_type":"code","execution_count":null,"id":"980e1962","metadata":{"id":"980e1962"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b2d65e36","metadata":{"id":"b2d65e36"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"1303c00f","metadata":{"id":"1303c00f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"deed6401","metadata":{"id":"deed6401"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6aed727d","metadata":{"id":"6aed727d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}